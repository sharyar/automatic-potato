{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder \n",
    "from sklearn.compose import ColumnTransformer\n",
    "from xgboost import XGBClassifier\n",
    "from joblib import dump, load"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Load and Process Data\n",
    "\n",
    "1. We start off with just loading our data via our csv files. \n",
    "2. The csv file does not have column names so we set those as well.\n",
    "3. Then we drop some columns that are irrelevant and also drop rows with null values \n",
    "4. We then set the right data types for the columns since they don't get inferred correctly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import LabelEncoder\n",
    "\n",
    "\n",
    "DATASET_FILE_PATH = \"data/adult-all.csv\"\n",
    "COLUMN_NAMES = [\n",
    "    \"age\",\n",
    "    \"workclass\",\n",
    "    \"fnlwgt\",\n",
    "    \"education\",\n",
    "    \"education-num\",\n",
    "    \"marital-status\",\n",
    "    \"occupation\",\n",
    "    \"relationship\",\n",
    "    \"race\",\n",
    "    \"sex\",\n",
    "    \"capital-gain\",\n",
    "    \"capital-loss\",\n",
    "    \"hours-per-week\",\n",
    "    \"native-country\",\n",
    "    \"label\"\n",
    "]\n",
    "\n",
    "\n",
    "def load_data() -> pl.DataFrame:\n",
    "    df = pl.read_csv(DATASET_FILE_PATH, has_header=False, null_values=[\"?\"])\n",
    "    df.columns = COLUMN_NAMES\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def pre_process_data(df: pl.DataFrame) -> pd.DataFrame:\n",
    "    # drop unnecessary columns\n",
    "    # drop nulls \n",
    "    # convert to pandas df for sklearn usage\n",
    "\n",
    "    processed_df = df.drop([\"fnlwgt\"]) \n",
    "    processed_df = processed_df.drop_nulls()\n",
    "    \n",
    "    processed_df = processed_df.to_pandas()\n",
    "    \n",
    "    return processed_df\n",
    "    \n",
    "    \n",
    "TrainingTuple = namedtuple(\"training_tuple\", [\"X_train\", \"y_train\", \"X_test\", \"y_test\", \"categorical_features\", \"numerical_features\"])\n",
    "def prepare_data_for_training(df: pd.DataFrame) -> TrainingTuple:\n",
    "    X, y = df.drop(\"label\", axis=1), df[\"label\"]\n",
    "    \n",
    "    cat_columns = X.select_dtypes(include=[\"object\", \"bool\"]).columns\n",
    "    num_columns = X.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    return TrainingTuple(X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test, \n",
    "                         categorical_features=cat_columns, numerical_features=num_columns)\n",
    "\n",
    "def train_model(training_tuple: TrainingTuple) -> Pipeline:    \n",
    "    encoder = LabelEncoder().fit(training_tuple.y_train)\n",
    "    encoded_y_train = encoder.transform(training_tuple.y_train)\n",
    "    encoded_y_test = encoder.transform(training_tuple.y_test)\n",
    "    \n",
    "    transformation_steps = [\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), training_tuple.categorical_features),\n",
    "        (\"num\", MinMaxScaler(), training_tuple.numerical_features)\n",
    "    ]\n",
    "    \n",
    "    model = XGBClassifier()\n",
    "    column_transformer = ColumnTransformer(transformers=transformation_steps)\n",
    "    \n",
    "    pipeline = Pipeline(\n",
    "        steps = [\n",
    "            ('col_transfomer', column_transformer),\n",
    "            ('model', model)\n",
    "        ]\n",
    "    )\n",
    "    pipeline.fit(training_tuple.X_train, encoded_y_train)\n",
    "    score = pipeline.score(training_tuple.X_test, encoded_y_test)\n",
    "    print(f\"Score for our final model on our test set! {score:.3f}\")\n",
    "    \n",
    "    return pipeline, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drift_data(df: pd.DataFrame, cols_to_drift: list, seed=42) -> pd.DataFrame:\n",
    "    rng = np.random.default_rng(seed)\n",
    "    df_drifted = df.copy()\n",
    "    for col in cols_to_drift:\n",
    "        mean_col = df[col].mean()\n",
    "        std_col = df[col].std()\n",
    "        df_drifted[col] = df_drifted[col] + rng.normal(mean_col/1.5, std_col, df_drifted.shape[0])\n",
    "        \n",
    "    return df_drifted\n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put it all together! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for our final model on our test set! 0.873\n",
      "Score for our final model on our drifted test set! 0.680\n"
     ]
    }
   ],
   "source": [
    "data = load_data()\n",
    "processed_data = pre_process_data(data)\n",
    "training_tuple = prepare_data_for_training(processed_data)\n",
    "pipeline, y_encoder = train_model(training_tuple)\n",
    "\n",
    "drifted_test_set_x = drift_data(training_tuple.X_test, [\"age\", \"hours-per-week\", \"capital-gain\", \"capital-loss\"])\n",
    "\n",
    "drifted_score = pipeline.score(drifted_test_set_x, y_encoder.transform(training_tuple.y_test))\n",
    "print(f\"Score for our final model on our drifted test set! {drifted_score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save our pipeline and encoder! \n",
    "dump(pipeline, \"models/adult_pipeline.joblib\")\n",
    "dump(y_encoder, \"models/adult_label_encoder.joblib\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "automatic-potato",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
